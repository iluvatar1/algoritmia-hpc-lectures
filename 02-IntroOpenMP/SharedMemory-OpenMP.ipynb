{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710eb72b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shared Memory: Threads and OpenMP\n",
    "\n",
    "- Shared memory is based on the thread model where threads (lightweight processes) share the same global memory.\n",
    "- There is no need for communication\n",
    "- Creating and destroying threads should be easy/cheap -> Fork/Join model\n",
    "- Limited by local memory\n",
    "  <div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f1/Fork_join.svg\" alt=\"Image Description\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7ffb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://passlab.github.io/OpenMPProgrammingBook/_images/2.png\" alt=\"Image Description\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "- [Introduction to OpenMP - Tim Mattson - Intel](https://www.youtube.com/watch?v=nE-xN4Bf8XI&list=PLLX-Q6B8xqZ8n8bwjGdzBJ25X2utwnoEG)\n",
    "\n",
    "- https://passlab.github.io/OpenMPProgrammingBook/MultiCoreMultiCPU/1_MIMDArchitecture.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc962e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## C++ example\n",
    "[OpenMP](https://www.openmp.org/) is the standard for using threads in HPC, for C/C++/Fortran. But you can also use [Posix threads](https://en.wikipedia.org/wiki/Pthreads?useskin=vector), [`std::threads`](https://en.cppreference.com/w/cpp/thread) from c++, an so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9525e23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:44:56.410355Z",
     "start_time": "2023-06-12T11:44:56.401374Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting openmp.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile openmp.cpp\n",
    "#include <iostream>\n",
    "#include <omp.h>\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "  std::cout << \"BEFORE\\n\";\n",
    "#pragma omp parallel\n",
    "  {\n",
    "    int thid = omp_get_thread_num();\n",
    "    std::cout << \"Hello world, from \" << thid << \"\\n\";\n",
    "  }\n",
    "  std::cout << \"AFTER\\n\";\n",
    "    \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a207283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:44:58.283896Z",
     "start_time": "2023-06-12T11:44:57.387472Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\r\n",
      "Hello world, from Hello world, from Hello world, from Hello world, from Hello world, from 1\r\n",
      "4\r\n",
      "0\r\n",
      "3\r\n",
      "2\r\n",
      "AFTER\r\n"
     ]
    }
   ],
   "source": [
    "# Compilation\n",
    "!g++-13 -fopenmp openmp.cpp -o openmp.x \n",
    "# execution\n",
    "!OMP_NUM_THREADS=5 ./openmp.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba2e788",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python example\n",
    "For Python, you can use the [threading](https://docs.python.org/3/library/threading.html#module-threading) (The  [Multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module actually generates processes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9695acfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:38:52.886094Z",
     "start_time": "2023-06-12T11:38:49.872080Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Thread-1 started\n",
      "Task Thread-2 started\n",
      "Task Thread-3 started\n",
      "Task Thread-4 started\n",
      "Task Thread-5 started\n",
      "Main thread continues executing\n",
      "Task Thread-2 completedTask Thread-3 completed\n",
      "Task Thread-4 completed\n",
      "Task Thread-5 completed\n",
      "Task Thread-1 completed\n",
      "\n",
      "All threads completed\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "# Define a function that will be executed in a separate thread\n",
    "def task(name):\n",
    "    print(f\"Task {name} started\")\n",
    "    time.sleep(3)  # Simulate some time-consuming task\n",
    "    print(f\"Task {name} completed\")\n",
    "\n",
    "# Create multiple threads and start them\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=task, args=(f\"Thread-{i+1}\",))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Allow some tasks to execute before starting others\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"Main thread continues executing\")\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"All threads completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46655e28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenMP in C++\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9b/OpenMP_language_extensions.svg\" alt=\"Image Description\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007ddf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T11:50:53.532611Z",
     "start_time": "2023-06-12T11:50:53.521111Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The [`openmp parallel`](https://www.openmp.org/spec-html/5.0/openmpse14.html) directive\n",
    "```c++\n",
    "#pragma omp parallel [clause ...]  newline \n",
    "                   if (scalar_expression) \n",
    "                   private (list) \n",
    "                   shared (list) \n",
    "                   default (shared | none) \n",
    "                   firstprivate (list) \n",
    "                   reduction (operator: list) \n",
    "                   copyin (list) \n",
    "                   num_threads (integer-expression)\n",
    " structured_block  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main(void)\n",
    "{\n",
    "    double x = 0;\n",
    "    {\n",
    "        double x = 20;\n",
    "    }\n",
    "    x += 10.0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76b1c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T13:21:43.759452Z",
     "start_time": "2023-06-17T13:21:42.968887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "zsh:1: command not found: free\n"
     ]
    }
   ],
   "source": [
    "!nproc\n",
    "!free -m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07daddb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Computing average of a large vector\n",
    "Let's assume that we have a large vector and we want to compute the average of its elements. First, think on how to parallelize the problem by using domain/problem decomposition\n",
    "<div style=\"text-align: center;\">\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "        <div style=\"text-align: center;\">\n",
    "    <img src=\"https://nyu-cds.github.io/python-mpi/fig/04-domain-decomp.png\" alt=\"Image Description\" width=\"400\">\n",
    "</div>\n",
    "    </td>\n",
    "    <td>\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://nyu-cds.github.io/python-mpi/fig/04-partitions.png\" alt=\"Image Description\" width=\"400\">\n",
    "</div>  \n",
    "    </td>\n",
    "  </tr>\n",
    "      <tr>\n",
    "    <td>\n",
    "        <div style=\"text-align: center;\">\n",
    "    <img src=\"https://stomp-userguide.pnnl.gov/estomp_guide/images/domain_decomposition.png\" alt=\"Image Description\" width=\"400\">\n",
    "</div>\n",
    "    </td>\n",
    "    <td>\n",
    "    <div style=\"text-align: center;\">\n",
    "    <img src=\"https://fun3d.larc.nasa.gov/dpw_near_grid.png\" alt=\"Image Description\" width=\"400\">\n",
    "</div>  \n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688884a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Domain decomposition: by hand\n",
    "Imagine that you have a vector of size $N$. And you have $nth$ threads. How will you split the work among them? What would be the limits for each thread? What variables should be private?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f522e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:28:40.528960Z",
     "start_time": "2023-06-12T12:28:40.521821Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile avg_openmp.cpp\n",
    "//# Solution: Manually splitting the domain\n",
    "#include <omp.h>\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "\n",
    "void init(std::vector<double> & array);\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    // resources\n",
    "    const int N = std::stoi(argv[1]);\n",
    "    std::vector<double> data(N, 0.0);\n",
    "    init(data);\n",
    "    double suma_total = 0.0;\n",
    "\n",
    "    double start = omp_get_wtime();\n",
    "    // calcular las sumas parciales\n",
    "#pragma omp parallel \n",
    "    {\n",
    "        int thid = omp_get_thread_num();\n",
    "        int nth = omp_get_num_threads();\n",
    "        int Nlocal = N/nth;\n",
    "\n",
    "        double suma = 0.0;\n",
    "        for(int ii = Nlocal*thid; ii < (thid+1)*Nlocal; ++ii) {\n",
    "            suma += data[ii];\n",
    "        }\n",
    "        //std::cout << thid << \"\\t\" << suma << \"\\n\";\n",
    "\t#pragma omp atomic update\n",
    "\tsuma_total += suma;\n",
    "    }\n",
    "    double end = omp_get_wtime();\n",
    "    std::cout << end-start << \"\\n\";\n",
    "    \n",
    "    // imprimir la informacion\n",
    "    std::cout << \"avg: \" << suma_total/N << \"\\n\";\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void init(std::vector<double> & array)\n",
    "{\n",
    "    for (auto & x : array) {\n",
    "        x = 1.7;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d62d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af81fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "977cb041",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Fortunately, `OpenMP` already does all the heavy-lifting for us, using the `parallel for` directive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84dbe696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:28:44.275865Z",
     "start_time": "2023-06-12T12:28:44.272669Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%writefile avg_parallelfor.cpp\n",
    "# Solution using parallel for\n",
    "#include <omp.h>\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "\n",
    "void init(std::vector<double> & array);\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    // resources\n",
    "    const int N = std::stoi(argv[1]);\n",
    "    std::vector<double> data(N, 0.0);\n",
    "    init(data);\n",
    "\n",
    "    double suma_total = 0.0;\n",
    "\n",
    "    double start = omp_get_wtime();\n",
    "    // calcular las sumas parciales\n",
    "#pragma omp parallel for reduction(+:suma_total)\n",
    "    for(int ii = 0; ii < N; ++ii) {\n",
    "        suma_total += data[ii];\n",
    "    }\n",
    "    double end = omp_get_wtime();\n",
    "    std::cout << end-start << \"\\n\";\n",
    "    \n",
    "    // imprimir la informacion\n",
    "    std::cout << \"avg: \" << suma_total/N << \"\\n\";\n",
    "    \n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void init(std::vector<double> & array)\n",
    "{\n",
    "    for (auto & x : array) {\n",
    "        x = 1.7;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e7221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84ab004",
   "metadata": {},
   "source": [
    "## Parallel metrics\n",
    "Compute the parallel metrics (speedup and parallel efficiency). Do you notice something special when reaching the number of cores? Use a small and a large system size. Use `slurm` to launch the jobs. Use the script builders or https://researchcomputing.princeton.edu/support/knowledge-base/scaling-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80401bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e49dfbb7",
   "metadata": {},
   "source": [
    "## Python implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f44e2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T16:57:09.133979Z",
     "start_time": "2023-06-17T16:57:03.594331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 50001490.589945585\n"
     ]
    }
   ],
   "source": [
    "# From chat gpt: Problematic, result depends on the number of threads\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of elements in the vector and the number of threads\n",
    "vector_size = 1000000000\n",
    "num_threads = 10\n",
    "\n",
    "# Generate a large vector of random numbers\n",
    "np.random.seed(10)\n",
    "vector = np.random.rand(vector_size)\n",
    "\n",
    "# Define a function that each thread will execute to compute the partial sum\n",
    "def compute_partial_sum(start, end, partial_sums):\n",
    "    partial_sum = np.sum(vector[start:end])\n",
    "    partial_sums.append(partial_sum)\n",
    "\n",
    "# Create a list to store the partial sums\n",
    "partial_sums = []\n",
    "\n",
    "# Create and start the threads\n",
    "threads = []\n",
    "chunk_size = vector_size // num_threads\n",
    "for i in range(num_threads):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    t = threading.Thread(target=compute_partial_sum, args=(start, end, partial_sums))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Compute the final mean\n",
    "mean = np.mean(partial_sums)\n",
    "\n",
    "print(\"Mean:\", mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c706cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:02:42.216213Z",
     "start_time": "2023-06-17T17:02:42.151622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1000247.2920411301\n"
     ]
    }
   ],
   "source": [
    "# \"Fix\" with a lock (problem persists)\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of elements in the vector and the number of threads\n",
    "vector_size = 10000000\n",
    "num_threads = 5\n",
    "\n",
    "# Generate a large vector of random numbers\n",
    "np.random.seed(10)\n",
    "vector = np.random.rand(vector_size)\n",
    "\n",
    "# Define a function that each thread will execute to compute the partial sum\n",
    "def compute_partial_sum(start, end, partial_sums, lock):\n",
    "    partial_sum = np.sum(vector[start:end])\n",
    "\n",
    "    # Acquire the lock before modifying the shared list\n",
    "    lock.acquire()\n",
    "    partial_sums.append(partial_sum)\n",
    "    lock.release()\n",
    "\n",
    "# Create a list to store the partial sums\n",
    "partial_sums = []\n",
    "\n",
    "# Create a lock for synchronizing access to the partial_sums list\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Create and start the threads\n",
    "threads = []\n",
    "chunk_size = vector_size // num_threads\n",
    "for i in range(num_threads):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "\n",
    "    t = threading.Thread(target=compute_partial_sum, args=(start, end, partial_sums, lock))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Compute the final mean\n",
    "mean = np.mean(partial_sums)\n",
    "\n",
    "print(\"Mean:\", mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6650bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T17:03:22.619732Z",
     "start_time": "2023-06-17T17:03:22.547175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2500618.230102826\n",
      "Mean: 0.5001236460205651\n"
     ]
    }
   ],
   "source": [
    "# chatGPT never got the fix: to compute the average with the total number of elements\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of elements in the vector and the number of threads\n",
    "vector_size = 10000000\n",
    "num_threads = 2\n",
    "\n",
    "# Generate a large vector of random numbers\n",
    "np.random.seed(10)\n",
    "vector = np.random.rand(vector_size)\n",
    "\n",
    "# Define a function that each thread will execute to compute the partial sum\n",
    "def compute_partial_sum(start, end, partial_sums):\n",
    "    partial_sum = np.sum(vector[start:end])\n",
    "    partial_sums.append(partial_sum)\n",
    "\n",
    "# Create a list to store the partial sums\n",
    "partial_sums = []\n",
    "\n",
    "# Create and start the threads\n",
    "threads = []\n",
    "chunk_size = vector_size // num_threads\n",
    "for i in range(num_threads):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    t = threading.Thread(target=compute_partial_sum, args=(start, end, partial_sums))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Compute the final mean\n",
    "mean = np.mean(partial_sums)\n",
    "print(\"Mean:\", mean)\n",
    "\n",
    "# This is the real problem, chatGPT does not understand it\n",
    "mean = np.sum(partial_sums)/vector_size\n",
    "print(\"Mean:\", mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7062c17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Workshop\n",
    "## Mean and standard deviation\n",
    "Write a program to compute the mean and the standard deviation for a large array using OpenMP, with only one reduction. Also compute the parallel metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0db84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "854f72cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Integral\n",
    "Write a program to compute the integral of the function , for $ x \\in [0, 10]$. Fill the following table:\n",
    "   |Threads|Runtime[s]|Speedup|Efficiency|\n",
    "   |---|---|---|---|\n",
    "   |||||\n",
    "  \n",
    "Use a constant and large $N$. What if you distribute $N$ among threads? what if you keep $N$ constant per thread?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d565d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2468a35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix-matrix multiplication\n",
    "Parallelize a Matrix-Matrix multiplication. Compare the performance when you use one, two, three, for threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8eaa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
